{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jjv13p4b1mpi"
      },
      "source": [
        "# ton_iot dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erU7GlQXk7nl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "from keras.utils import to_categorical\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "import pandas as pd # used for handling the dataset\n",
        "import numpy as np # used for handling numbers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "# necessary package for DL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# added import\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
        "import time\n",
        "import sys\n",
        "from typing import Dict, Optional, Tuple\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import roc_curve, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWhmYFIvlF5r"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "ton_iot  = pd.read_csv(\"/content/drive/MyDrive/ton_iot/Train_Test_Network.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcU9pCVwl47G"
      },
      "outputs": [],
      "source": [
        "df_y      = ton_iot['label']                 # utilisée pour le supervised learning\n",
        "ton_iot_1 = ton_iot.drop  ('label' , axis=1) # utilisée pour le supervised learning\n",
        "ton_iot_1 = ton_iot_1.drop('src_ip', axis=1) # peut faussé les résultats\n",
        "ton_iot_1 = ton_iot_1.drop('dst_ip', axis=1) # peut faussé les résultats\n",
        "ton_iot_1 = ton_iot_1.drop('type'  , axis=1) # peut faussé les résultats\n",
        "ton_iot_1 = ton_iot_1.drop('ts'  , axis=1) # peut faussé les résultats\n",
        "\n",
        "\n",
        "# ces features sont utilisée je pense pour labeled the dataset\n",
        "ton_iot_1 = ton_iot_1.drop('weird_notice'  , axis=1) # contient que des valeurs 'F', '-'\n",
        "ton_iot_1 = ton_iot_1.drop('http_version'  , axis=1) # contient que des valeurs '-', '1.1'\n",
        "ton_iot_1 = ton_iot_1.drop('weird_addl'  , axis=1)   # contient que des valeurs '-', '1.1'\n",
        "ton_iot_1 = ton_iot_1.drop('weird_name'  , axis=1)   # contient que des valeurs '-', '1.1'\n",
        "\n",
        "#convert boolean value to integer boolean value\n",
        "ton_iot_1.dns_AA = ton_iot_1.dns_AA.replace({'-': 0, 'F': 0, 'T': 1})\n",
        "ton_iot_1.dns_RD = ton_iot_1.dns_RD.replace({'-': 0, 'F': 0, 'T': 1})\n",
        "ton_iot_1.dns_RA = ton_iot_1.dns_RA.replace({'-': 0, 'F': 0, 'T': 1})\n",
        "ton_iot_1.dns_rejected    = ton_iot_1.dns_rejected.replace({'-': 0, 'F': 0, 'T': 1})\n",
        "ton_iot_1.ssl_resumed     = ton_iot_1.ssl_resumed.replace({'-': 0, 'F': 0, 'T': 1})\n",
        "ton_iot_1.ssl_established = ton_iot_1.ssl_established.replace({'-': 0, 'F': 0, 'T': 1})\n",
        "\n",
        "# transform http_trans_depth from object to integer\n",
        "ton_iot_1.http_trans_depth = ton_iot_1.http_trans_depth.replace({'-': 0})\n",
        "ton_iot_1['http_trans_depth'] = ton_iot_1['http_trans_depth'].astype(str).astype(int)\n",
        "\n",
        "df_ordinal_x = ton_iot_1[[\"http_uri\", \"http_user_agent\", \"dns_query\"]]\n",
        "transformer = OrdinalEncoder()\n",
        "transformed  = transformer.fit_transform(df_ordinal_x)\n",
        "df_ordinal_transformed_x = pd.DataFrame(transformed, columns=[\"http_uri\", \"http_user_agent\", \"dns_query\"])\n",
        "\n",
        "df_categori_x = ton_iot_1[[\"proto\", \"service\", \"conn_state\", \"ssl_version\", \"ssl_cipher\", \"ssl_subject\", \"ssl_issuer\", \"http_method\", \"http_orig_mime_types\", \"http_resp_mime_types\"]]\n",
        "\n",
        "transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "transformed = transformer.fit_transform(df_categori_x).toarray()\n",
        "\n",
        "transformer.get_feature_names_out()\n",
        "\n",
        "df_categori_transformed_x = pd.DataFrame(transformed, columns=transformer.get_feature_names_out())\n",
        "\n",
        "\n",
        "df_num_x = ton_iot_1[[\"src_port\", \"dst_port\", \"duration\", \"src_bytes\", \"dst_bytes\", \"missed_bytes\", \"src_pkts\", \"src_ip_bytes\", \"dst_pkts\", \"dst_ip_bytes\", \"dns_qclass\", \"dns_qtype\", \"dns_rcode\", \"http_trans_depth\", \"http_request_body_len\", \"http_response_body_len\", \"http_status_code\"]].astype(float)\n",
        "df_num_x[\"http_uri\"]       = df_ordinal_transformed_x[\"http_uri\"]\n",
        "df_num_x[\"http_user_agent\"]= df_ordinal_transformed_x[\"http_user_agent\"]\n",
        "df_num_x[\"dns_query\"]      = df_ordinal_transformed_x[\"dns_query\"]\n",
        "\n",
        "def prepare_inputs(X_train):\n",
        "    oe = StandardScaler()\n",
        "    oe.fit(X_train)\n",
        "    X_train_enc = oe.transform(X_train)\n",
        "    return X_train_enc\n",
        "\n",
        "#normlize the numerical data\n",
        "df_num_norm = prepare_inputs(df_num_x)\n",
        "df_num_norm = pd.DataFrame(df_num_norm, columns = df_num_x.columns)\n",
        "\n",
        "#concatenate numerical and categorical data to splite them to test and train\n",
        "df_all = pd.concat([df_num_norm, df_categori_transformed_x], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24Bky6gSl6OX"
      },
      "outputs": [],
      "source": [
        "df_train_X, df_test_X, df_train_y, df_test_y = train_test_split(df_all, df_y, test_size=0.2, random_state=42)\n",
        "\n",
        "# taille du model\n",
        "taille_variable1 = sys.getsizeof(df_train_X)\n",
        "taille_variable2 = sys.getsizeof(df_train_y)\n",
        "taille_total = taille_variable1 + taille_variable2\n",
        "print(f\"La taille du model est : {taille_total} octets\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJUm6nZ9-d_Y"
      },
      "outputs": [],
      "source": [
        "input = 84\n",
        "model = Sequential()\n",
        "model.add(Dense(60, input_dim=input, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(40, activation='relu'))\n",
        "model.add(Dense(30, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                    tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                    tf.keras.metrics.Precision(),\n",
        "                                                                    tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                    tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                    tf.keras.metrics.FalseNegatives()])\n",
        "start_time = time.time()\n",
        "model.fit(df_train_X, df_train_y, epochs=100) #100\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "# temps d'execution\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "# taille du model\n",
        "taille_variable = sys.getsizeof(model)\n",
        "print(f\"La taille de la variable est : {taille_variable} octets\")\n",
        "loss, acc, auc, precision, recall, tp, tn, fp, fn= model.evaluate(df_test_X, df_test_y, verbose=2)\n",
        "\n",
        "# Making predictions on the test set to obtain probabilities\n",
        "predictions_proba = model.predict(df_test_X).ravel()\n",
        "# Deriving classes based on a threshold (e.g., 0.5)\n",
        "predictions = np.where(predictions_proba >= 0.5, 1, 0)\n",
        "# Calculating F1 score\n",
        "f1 = f1_score(df_test_y, predictions)\n",
        "# print f1 score\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5ZowxANiLQb"
      },
      "source": [
        "# FL with flower"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FL setup"
      ],
      "metadata": {
        "id": "e_HUnnnnlMQn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW05L8-1NK-t"
      },
      "outputs": [],
      "source": [
        "pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlNaniyIiOHZ"
      },
      "outputs": [],
      "source": [
        "pip install flwr[\"simulation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2FqTJvWjFp6"
      },
      "outputs": [],
      "source": [
        "import flwr as fl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Xo1BEWWoc3I"
      },
      "outputs": [],
      "source": [
        "def print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn):\n",
        "  print(\"==============list_f1_score=================\")\n",
        "  for i in list_f1_score :\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_auc==============\")\n",
        "  for i in list_auc:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_precision==============\")\n",
        "  for i in list_precision:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_recall==============\")\n",
        "  for i in list_recall:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_tp==============\")\n",
        "  for i in list_tp:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_tn==============\")\n",
        "  for i in list_tn:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_fp==============\")\n",
        "  for i in list_fp:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_fn==============\")\n",
        "  for i in list_fn:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_la-jlxjWKW"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=1, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEtHMeqYjjY9"
      },
      "outputs": [],
      "source": [
        "def func_client_fn(model_fl, x_train_all, y_train_all):\n",
        "\n",
        "  x_train_all = x_train_all\n",
        "  y_train_all = y_train_all\n",
        "\n",
        "  def client_fn(cid: str) -> fl.client.Client:\n",
        "\n",
        "      print('########################################## cid= ',cid,' ##########################################')\n",
        "      # Load data partition (divide dataset into NUM_CLIENTS distinct partitions)\n",
        "      partition_size = math.floor(len(x_train_all) / NUM_CLIENTS)\n",
        "      idx_from, idx_to = int(cid) * partition_size, (int(cid) + 1) * partition_size\n",
        "      x_train_all_part = x_train_all[idx_from:idx_to]\n",
        "      y_train_all_part = y_train_all[idx_from:idx_to]\n",
        "\n",
        "      x_train_all_part, X_test_all, y_train_all_part, y_test_all = train_test_split(x_train_all, y_train_all, test_size=0.1)\n",
        "\n",
        "      # Create and return client\n",
        "      return FlowerClient(model_fl, x_train_all_part, y_train_all_part, X_test_all, y_test_all)\n",
        "\n",
        "  return client_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqtJ_QIzkCD9"
      },
      "outputs": [],
      "source": [
        "def get_eval_fn(model, x_test_arr_val, y_test_arr_val):\n",
        "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
        "    global list_f1_score\n",
        "    global list_auc\n",
        "    global list_precision\n",
        "    global list_recall\n",
        "    global list_tp\n",
        "    global list_tn\n",
        "    global list_fp\n",
        "    global list_fn\n",
        "    global model_xai\n",
        "\n",
        "    x_test_arr_val = x_test_arr_val\n",
        "    y_test_arr_val = y_test_arr_val\n",
        "\n",
        "\n",
        "    # The `evaluate` function will be called after every round\n",
        "    def evaluate(server_round: int, parameters: fl.common.NDArrays, config: Dict[str, fl.common.Scalar],) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "\n",
        "        model.set_weights(parameters)  # Update model with the latest parameters\n",
        "        loss, accuracy, auc, precision, recall, tp, tn, fp, fn = model.evaluate(x_test_arr_val, y_test_arr_val)\n",
        "\n",
        "        # Making predictions on the test set to obtain probabilities\n",
        "        predictions_proba = model.predict(x_test_arr_val).ravel()\n",
        "\n",
        "        # Deriving classes based on a threshold (e.g., 0.5)\n",
        "        predictions = np.where(predictions_proba >= 0.5, 1, 0)\n",
        "\n",
        "        # Calculating F1 score\n",
        "        f1 = f1_score(y_test_arr_val, predictions)\n",
        "        list_f1_score.append(f1)\n",
        "        list_auc.append(auc)\n",
        "        list_precision.append(precision)\n",
        "        list_recall.append(recall)\n",
        "        list_tp.append(tp)\n",
        "        list_tn.append(tn)\n",
        "        list_fp.append(fp)\n",
        "        list_fn.append(fn)\n",
        "\n",
        "        if accuracy > 0.9804 :\n",
        "          model_xai = model\n",
        "          sys.exit()\n",
        "\n",
        "\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "\n",
        "    return evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIhn7qn1kfJz"
      },
      "outputs": [],
      "source": [
        "list_f1_score =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (x_fraction, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(60, input_dim=84, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(40, activation='relu'))\n",
        "    model_cent.add(Dense(30, activation='relu'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='sigmoid'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=x_fraction,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=200),\n",
        "        strategy=strategy,\n",
        "    )\n",
        "\n",
        "    print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test number of clients"
      ],
      "metadata": {
        "id": "MNwD-_samARr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### number of clients = 2 & local epochs = 1 and fraction fit = 1"
      ],
      "metadata": {
        "id": "ZxiqfCsJmCWu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hib8wHrGVSsX"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 2\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGhwzXiOyCHQ"
      },
      "outputs": [],
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### number of clients = 4 & local epochs = 1 and fraction fit = 1"
      ],
      "metadata": {
        "id": "SDk9T9iqmGJ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oa3fei2aiiY8"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 4\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4-RjLSayNtD"
      },
      "outputs": [],
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### number of clients = 8 & local epochs = 1 and fraction fit = 1"
      ],
      "metadata": {
        "id": "WP0KopjMmHnd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dP33I_P3ijot"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 8\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jm7J5FJVySXJ"
      },
      "outputs": [],
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pspOgU2ipwm"
      },
      "source": [
        "## tester fractions fit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fraction fit = 0.1 & number of clients = 8 & local epochs = 1"
      ],
      "metadata": {
        "id": "ZtgPpjHCmLwI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eNgmBdiXljd"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 8\n",
        "start_time = time.time()\n",
        "FL_process(0.1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkNj-txMLa2M"
      },
      "outputs": [],
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fraction fit = 0.5 & number of clients = 8 & local epochs = 1"
      ],
      "metadata": {
        "id": "PqYeOeGDmRXE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmqnGtL2iuQx"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "FL_process(0.5, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKMuMbLuLdSV"
      },
      "outputs": [],
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fraction fit = 1 & number of clients = 8 & local epochs = 1\n",
        "- aleready tested"
      ],
      "metadata": {
        "id": "R1TV0iE6mVSQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test local epochs"
      ],
      "metadata": {
        "id": "3S7ukYO2nj5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### local epochs = 1 & fraction fit = 1 & number of clients = 8\n",
        "- already tested"
      ],
      "metadata": {
        "id": "c4m2dScgnIYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### local epochs = 2 & fraction fit = 1 & number of clients = 8"
      ],
      "metadata": {
        "id": "HhjcWoPcnVDC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9kKZtIVLQva"
      },
      "outputs": [],
      "source": [
        "# test local epochs with 2\n",
        "\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=2, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "\n",
        "list_f1_score =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(60, input_dim=84, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(40, activation='relu'))\n",
        "    model_cent.add(Dense(30, activation='relu'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='sigmoid'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=1,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(8 * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=8,\n",
        "        config=fl.server.ServerConfig(num_rounds=200),\n",
        "        strategy=strategy,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6X3i47lHL25I"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "FL_process(df_train_X, df_train_y, df_test_X, df_test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7Njv0KonFrc"
      },
      "outputs": [],
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### local epochs = 5 & fraction fit = 1 & number of clients = 8"
      ],
      "metadata": {
        "id": "lUJtWPjxnbdG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOmX2McqLqMS"
      },
      "outputs": [],
      "source": [
        "# test local epoch with 5\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=5, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "\n",
        "list_f1_score =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(60, input_dim=84, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(40, activation='relu'))\n",
        "    model_cent.add(Dense(30, activation='relu'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='sigmoid'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=1,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(8 * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=8,\n",
        "        config=fl.server.ServerConfig(num_rounds=200),\n",
        "        strategy=strategy,\n",
        "    )\n",
        "\n",
        "    print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOqWNtprnMF1"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "FL_process(df_train_X, df_train_y, df_test_X, df_test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JB8iXyY5nRwC"
      },
      "outputs": [],
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### local epochs = 8 & fraction fit = 1 & number of clients = 8"
      ],
      "metadata": {
        "id": "C9FvCmp7netl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP2cRgE5LtVd"
      },
      "outputs": [],
      "source": [
        "# test local epoch with 8\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=8, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "\n",
        "list_f1_score =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(60, input_dim=84, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(40, activation='relu'))\n",
        "    model_cent.add(Dense(30, activation='relu'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='sigmoid'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=1,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(8 * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=8,\n",
        "        config=fl.server.ServerConfig(num_rounds=200),\n",
        "        strategy=strategy,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md6jUPGdMGRR"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "FL_process(df_train_X, df_train_y, df_test_X, df_test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNsm4iLynUtQ"
      },
      "outputs": [],
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O89sJomoLhbR"
      },
      "source": [
        "## XAI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### local epochs = 8 & fraction fit = 1 & number of clients = 8"
      ],
      "metadata": {
        "id": "wR0eqrfwRdRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=8, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "\n",
        "list_f1_score =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(60, input_dim=84, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(40, activation='relu'))\n",
        "    model_cent.add(Dense(30, activation='relu'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='sigmoid'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=1,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=8,\n",
        "        config=fl.server.ServerConfig(num_rounds=200),\n",
        "        strategy=strategy,\n",
        "    )\n",
        "\n",
        "    print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "9o8MG2u8oKBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "FL_process(df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "BtEaOSZQoy_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_acc, list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "f1Sqv4EioJWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "explainer   = shap.Explainer(model_xai, df_train_X.values)\n",
        "shap_values = explainer(df_test_X)\n",
        "\n",
        "shap.plots.beeswarm(shap_values, max_display=8)\n",
        "shap.plots.bar(shap_values, max_display=8)"
      ],
      "metadata": {
        "id": "2lCHTKAUn5Gs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "Jjv13p4b1mpi",
        "F5ZowxANiLQb",
        "e_HUnnnnlMQn",
        "MNwD-_samARr",
        "ZxiqfCsJmCWu",
        "SDk9T9iqmGJ8",
        "WP0KopjMmHnd",
        "_pspOgU2ipwm",
        "ZtgPpjHCmLwI",
        "PqYeOeGDmRXE",
        "3S7ukYO2nj5t",
        "HhjcWoPcnVDC",
        "lUJtWPjxnbdG",
        "C9FvCmp7netl",
        "O89sJomoLhbR",
        "wR0eqrfwRdRJ"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}