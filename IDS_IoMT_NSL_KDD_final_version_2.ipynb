{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "rHpuVgcZXN28",
        "gJ0lPpwygCaZ",
        "sxC92MYngL99",
        "tQhH0UCRgPXq",
        "Gf0F3sKpgXdN",
        "jBphB6-w9FeV",
        "QufQjCwILU24",
        "rxlzwFWygpUy",
        "AF0SCNB-hyds",
        "-shsKJ0ngtoN",
        "dxDJnJWWkUaz",
        "Fg8aHhBr7Ufr",
        "tQQ7WfDi7iT9",
        "kJfs1ENP7ubh",
        "YLbEZEs0OvXo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# centralized IDS"
      ],
      "metadata": {
        "id": "_WrYwQ6EXS7B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWbD5DiwVdHY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # used for handling the dataset\n",
        "import numpy as np # used for handling numbers\n",
        "from collections import Counter\n",
        "import random\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# necessary package for DL\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# added import\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
        "import time\n",
        "import sys\n",
        "from typing import Dict, Optional, Tuple\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://colab.research.google.com/drive/1hvVW5GMSc5qRmtCKZAImW3gZ2Qa-vx9V#scrollTo=jk1CNtc9aG55\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jkNAYwwnVjL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/KDDTrain+.txt\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/KDDTest+.txt\")"
      ],
      "metadata": {
        "id": "Z_1xNPbEVkl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = (['duration'\n",
        ",'protocol_type'\n",
        ",'service'\n",
        ",'flag'\n",
        ",'src_bytes'\n",
        ",'dst_bytes'\n",
        ",'land'\n",
        ",'wrong_fragment'\n",
        ",'urgent'\n",
        ",'hot'\n",
        ",'num_failed_logins'\n",
        ",'logged_in'\n",
        ",'num_compromised'\n",
        ",'root_shell'\n",
        ",'su_attempted'\n",
        ",'num_root'\n",
        ",'num_file_creations'\n",
        ",'num_shells'\n",
        ",'num_access_files'\n",
        ",'num_outbound_cmds'\n",
        ",'is_host_login'\n",
        ",'is_guest_login'\n",
        ",'count'\n",
        ",'srv_count'\n",
        ",'serror_rate'\n",
        ",'srv_serror_rate'\n",
        ",'rerror_rate'\n",
        ",'srv_rerror_rate'\n",
        ",'same_srv_rate'\n",
        ",'diff_srv_rate'\n",
        ",'srv_diff_host_rate'\n",
        ",'dst_host_count'\n",
        ",'dst_host_srv_count'\n",
        ",'dst_host_same_srv_rate'\n",
        ",'dst_host_diff_srv_rate'\n",
        ",'dst_host_same_src_port_rate'\n",
        ",'dst_host_srv_diff_host_rate'\n",
        ",'dst_host_serror_rate'\n",
        ",'dst_host_srv_serror_rate'\n",
        ",'dst_host_rerror_rate'\n",
        ",'dst_host_srv_rerror_rate'\n",
        ",'attack'\n",
        ",'level'])\n",
        "\n",
        "df.columns = columns\n",
        "test_df.columns = columns\n",
        "\n",
        "dataset = pd.concat([df, test_df])\n",
        "\n",
        "#keep attack_cat for further use\n",
        "df_attack_cat = dataset['attack']\n",
        "\n",
        "# map normal to 0, all attacks to 1\n",
        "is_attack = dataset.attack.map(lambda a: 0 if a == 'normal' else 1)\n",
        "\n",
        "#data_with_attack = df.join(is_attack, rsuffix='_flag')\n",
        "dataset['attack_flag'] = is_attack\n",
        "\n",
        "# delete attribut used to label the dataset\n",
        "dataset = dataset.drop('level', axis=1)\n",
        "dataset = dataset.drop('attack', axis=1)\n",
        "\n",
        "# get object attributs\n",
        "df_object = dataset[['protocol_type', 'service', 'flag']]\n",
        "\n",
        "# get label data\n",
        "df_y = dataset['attack_flag']\n",
        "\n",
        "# get numerical attributs\n",
        "df_numerical = dataset.drop('protocol_type', axis=1)\n",
        "df_numerical = df_numerical.drop('service', axis=1)\n",
        "df_numerical = df_numerical.drop('flag', axis=1)\n",
        "df_numerical = df_numerical.drop('attack_flag', axis=1)\n",
        "\n",
        "# create a OneHotEncoder object\n",
        "std = StandardScaler()\n",
        "\n",
        "# fit and transform the single column\n",
        "encoded_column = std.fit_transform(df_numerical)\n",
        "\n",
        "# create a new dataframe with the encoded column\n",
        "df_num = pd.DataFrame(encoded_column, columns=df_numerical.columns)\n",
        "\n",
        "# create a OneHotEncoder object\n",
        "ohe = OneHotEncoder()\n",
        "\n",
        "# fit and transform the single column\n",
        "encoded_column = ohe.fit_transform(df_object).toarray()\n",
        "\n",
        "# create a new dataframe with the encoded column\n",
        "df_obj = pd.DataFrame(encoded_column, columns=ohe.get_feature_names_out())\n",
        "\n",
        "df_preprocessed = pd.concat([df_obj, df_num], axis=1)"
      ],
      "metadata": {
        "id": "Ep30xapKVmDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_X, df_test_X, df_train_y, df_test_y = train_test_split(df_preprocessed, df_y, test_size=0.2)\n",
        "\n",
        "# taille du model\n",
        "taille_variable1 = sys.getsizeof(df_train_X)\n",
        "taille_variable2 = sys.getsizeof(df_train_y)\n",
        "taille_total = taille_variable1 + taille_variable2\n",
        "print(f\"La taille du model est : {taille_total} octets\")"
      ],
      "metadata": {
        "id": "LDEoVUme7tS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = 122\n",
        "model = Sequential()\n",
        "model.add(Dense(80, input_dim=input, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(40, activation='relu'))\n",
        "model.add(Dense(30, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                    tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                    tf.keras.metrics.Precision(),\n",
        "                                                                    tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                    tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                    tf.keras.metrics.FalseNegatives()])\n",
        "start_time = time.time()\n",
        "model.fit(df_train_X, df_train_y, epochs=50) #15\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "# temps d'execution\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "# taille du model\n",
        "taille_variable = sys.getsizeof(model)\n",
        "print(f\"La taille de la variable est : {taille_variable} octets\")\n",
        "loss, acc, auc, precision, recall, tp, tn, fp, fn= model.evaluate(df_test_X, df_test_y, verbose=2)\n",
        "\n",
        "# Making predictions on the test set to obtain probabilities\n",
        "predictions_proba = model.predict(df_test_X).ravel()\n",
        "# Deriving classes based on a threshold (e.g., 0.5)\n",
        "predictions = np.where(predictions_proba >= 0.5, 1, 0)\n",
        "# Calculating F1 score\n",
        "f1 = f1_score(df_test_y, predictions)\n",
        "# print f1 score\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "E7WE8gs_WEbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FL IDS"
      ],
      "metadata": {
        "id": "rHpuVgcZXN28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup FL"
      ],
      "metadata": {
        "id": "gJ0lPpwygCaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap"
      ],
      "metadata": {
        "id": "8zwDQ_LVXJEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install flwr[\"simulation\"]"
      ],
      "metadata": {
        "id": "M8weR4Ar8DPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import flwr as fl"
      ],
      "metadata": {
        "id": "rXPfmll58DRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_results (list_acc, list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn):\n",
        "  print(\"==============list_acc=================\")\n",
        "  for i in list_acc :\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_f1_score=================\")\n",
        "  for i in list_f1_score :\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_auc==============\")\n",
        "  for i in list_auc:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_precision==============\")\n",
        "  for i in list_precision:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_recall==============\")\n",
        "  for i in list_recall:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_tp==============\")\n",
        "  for i in list_tp:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_tn==============\")\n",
        "  for i in list_tn:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_fp==============\")\n",
        "  for i in list_fp:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_fn==============\")\n",
        "  for i in list_fn:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "LeD47auD8DV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=1, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}"
      ],
      "metadata": {
        "id": "nKHc0xd48DYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func_client_fn(model_fl, x_train_all, y_train_all):\n",
        "\n",
        "  x_train_all = x_train_all\n",
        "  y_train_all = y_train_all\n",
        "\n",
        "  def client_fn(cid: str) -> fl.client.Client:\n",
        "\n",
        "      print('########################################## cid= ',cid,' ##########################################')\n",
        "      # Load data partition (divide dataset into NUM_CLIENTS distinct partitions)\n",
        "      partition_size = math.floor(len(x_train_all) / NUM_CLIENTS)\n",
        "      idx_from, idx_to = int(cid) * partition_size, (int(cid) + 1) * partition_size\n",
        "      x_train_all_part = x_train_all[idx_from:idx_to]\n",
        "      y_train_all_part = y_train_all[idx_from:idx_to]\n",
        "\n",
        "      x_train_all_part, X_test_all, y_train_all_part, y_test_all = train_test_split(x_train_all, y_train_all, test_size=0.1)\n",
        "\n",
        "      # Create and return client\n",
        "      return FlowerClient(model_fl, x_train_all_part, y_train_all_part, X_test_all, y_test_all)\n",
        "\n",
        "  return client_fn"
      ],
      "metadata": {
        "id": "09LdtaAa8Dbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_eval_fn(model, x_test_arr_val, y_test_arr_val):\n",
        "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
        "    global list_f1_score\n",
        "    global list_acc\n",
        "    global list_auc\n",
        "    global list_precision\n",
        "    global list_recall\n",
        "    global list_tp\n",
        "    global list_tn\n",
        "    global list_fp\n",
        "    global list_fn\n",
        "    global model_xai\n",
        "\n",
        "    x_test_arr_val = x_test_arr_val\n",
        "    y_test_arr_val = y_test_arr_val\n",
        "\n",
        "\n",
        "    # The `evaluate` function will be called after every round\n",
        "    def evaluate(server_round: int, parameters: fl.common.NDArrays, config: Dict[str, fl.common.Scalar],) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "\n",
        "        model.set_weights(parameters)  # Update model with the latest parameters\n",
        "        loss, accuracy, auc, precision, recall, tp, tn, fp, fn = model.evaluate(x_test_arr_val, y_test_arr_val)\n",
        "\n",
        "        # Making predictions on the test set to obtain probabilities\n",
        "        predictions_proba = model.predict(x_test_arr_val).ravel()\n",
        "\n",
        "        # Deriving classes based on a threshold (e.g., 0.5)\n",
        "        predictions = np.where(predictions_proba >= 0.5, 1, 0)\n",
        "\n",
        "        # Calculating F1 score\n",
        "        f1 = f1_score(y_test_arr_val, predictions)\n",
        "        list_acc.append(accuracy)\n",
        "        list_f1_score.append(f1)\n",
        "        list_auc.append(auc)\n",
        "        list_precision.append(precision)\n",
        "        list_recall.append(recall)\n",
        "        list_tp.append(tp)\n",
        "        list_tn.append(tn)\n",
        "        list_fp.append(fp)\n",
        "        list_fn.append(fn)\n",
        "\n",
        "        if accuracy > 0.9902 :\n",
        "          model_xai = model\n",
        "          sys.exit()\n",
        "\n",
        "\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "\n",
        "    return evaluate"
      ],
      "metadata": {
        "id": "a2TP_IxV8Dfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_f1_score =[]\n",
        "list_acc =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (x_fraction, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(80, input_dim=122, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(40, activation='relu'))\n",
        "    model_cent.add(Dense(30, activation='relu'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='relu'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=x_fraction,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=50),\n",
        "        strategy=strategy,\n",
        "    )"
      ],
      "metadata": {
        "id": "_Jk74gPG8DiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test number of clients"
      ],
      "metadata": {
        "id": "sxC92MYngL99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### number of clients = 2 & fraction fit = 1 & local epochs = 1"
      ],
      "metadata": {
        "id": "tQhH0UCRgPXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 2\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "Z6VBHyEp8Dk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_acc, list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "AnQJu_jU8Dng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vb2EgCllLfzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### number of clients = 4 & fraction fit = 1 & local epochs = 1"
      ],
      "metadata": {
        "id": "Gf0F3sKpgXdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 4\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "WvioDW1Y8DqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_acc, list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "zHpi3Hhb8Dsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### number of clients = 8 & fraction fit = 1 & local epochs = 1"
      ],
      "metadata": {
        "id": "jBphB6-w9FeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 8\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "guWC2HyJ8D0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_acc, list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "B4zbiMav9HRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### number of clients = 12 & fraction fit = 1 & local epochs = 1"
      ],
      "metadata": {
        "id": "QufQjCwILU24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 12\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "a_h1Ki2x7EJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_acc, list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "Ck9DpOdQ7F7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test Fraction fit"
      ],
      "metadata": {
        "id": "rxlzwFWygpUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fraction fit = 0.1 & local epochs = 1 & number of clients = 8"
      ],
      "metadata": {
        "id": "AF0SCNB-hyds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 8\n",
        "start_time = time.time()\n",
        "FL_process(0.1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "sEo6Z_CkiLJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_acc, list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "HzDnXd80iLUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fraction fit = 0.5 & local epochs = 1 & number of clients = 8\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-shsKJ0ngtoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "FL_process(0.5, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "lpkfUSS99I4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_acc, list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "8P4UrhAd9KUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fraction fit = 1 & local epochs = 1 & number of clients = 8\n",
        "- aleardy tested"
      ],
      "metadata": {
        "id": "odyj7Dnnh2X8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test local epochs"
      ],
      "metadata": {
        "id": "dxDJnJWWkUaz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test local epochs = 1 & Fraction fit = 1 & number of clients = 8\n",
        "- aleardy tested"
      ],
      "metadata": {
        "id": "mrCf_4gF6foM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test with 2 epochs & Fraction fit = 1 & number of clients = 8"
      ],
      "metadata": {
        "id": "Fg8aHhBr7Ufr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=2, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "list_f1_score =[]\n",
        "list_acc =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (x_fraction, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(80, input_dim=122, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(40, activation='relu'))\n",
        "    model_cent.add(Dense(30, activation='relu'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='relu'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=x_fraction,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=50),\n",
        "        strategy=strategy,\n",
        "    )"
      ],
      "metadata": {
        "id": "J9a4SzRQ7S1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 8\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "PDbebDeL7b4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_acc, list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "SZogeRoh7cDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### local epochs = 5 & Fraction fit = 1 & number of clients = 8"
      ],
      "metadata": {
        "id": "tQQ7WfDi7iT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=5, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "list_f1_score =[]\n",
        "list_acc =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (x_fraction, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(80, input_dim=122, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(40, activation='relu'))\n",
        "    model_cent.add(Dense(30, activation='relu'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='relu'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=x_fraction,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=50),\n",
        "        strategy=strategy,\n",
        "    )"
      ],
      "metadata": {
        "id": "NPOd3yQF7hSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 8\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "PBfSh59w7oLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_acc, list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "6Mw8n8eU7oSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### local epochs = 8 & Fraction fit = 1 & number of clients = 8"
      ],
      "metadata": {
        "id": "kJfs1ENP7ubh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=8, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "list_f1_score =[]\n",
        "list_acc =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (x_fraction, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(80, input_dim=122, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(40, activation='relu'))\n",
        "    model_cent.add(Dense(30, activation='relu'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='relu'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=x_fraction,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=50),\n",
        "        strategy=strategy,\n",
        "    )"
      ],
      "metadata": {
        "id": "N-HrSE_3jNIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 8\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "8QuY95r5jNb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_acc, list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "6xGSLIsXjNng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XAI"
      ],
      "metadata": {
        "id": "YLbEZEs0OvXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### local epochs = 8 & Fraction fit = 1 & number of clients = 8"
      ],
      "metadata": {
        "id": "V4A3-36ONriH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=8, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "list_f1_score =[]\n",
        "list_acc =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(80, input_dim=122, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(40, activation='relu'))\n",
        "    model_cent.add(Dense(30, activation='relu'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='relu'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=1,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=8,\n",
        "        config=fl.server.ServerConfig(num_rounds=50),\n",
        "        strategy=strategy,\n",
        "    )"
      ],
      "metadata": {
        "id": "_NQ-zLkyipV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "FL_process(df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "FkuZZSbSo-bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_acc, list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "p1PaafuNPGvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "explainer   = shap.Explainer(model_xai, df_train_X.values)\n",
        "shap_values = explainer(df_test_X)\n",
        "\n",
        "shap.plots.beeswarm(shap_values)\n",
        "shap.plots.bar(shap_values)"
      ],
      "metadata": {
        "id": "m17PPZea9NTC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}