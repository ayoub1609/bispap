{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "AZBXhgrfTKoQ",
        "mzX_kfbOTO_S",
        "sl5QhPIeFsJB",
        "ibFTJNy8FwvG",
        "933VeyyoF0PH",
        "y2dZcbYeF67V",
        "ZxsMbJAu-Ukd",
        "_HnCOPVF5yyg",
        "mTLkZzGLGGny",
        "N55dDDPxGJsd",
        "kVEwpAggJcAO",
        "vB4lLTUvJcL8",
        "0RPGrwrZn4_-",
        "ZVge-znSH7uS",
        "LHM7lLWvpSXc",
        "815QDMLIpjVs",
        "Ij2yDE6ZpwuO",
        "MQnmUMCjPLKw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# centralized IDS"
      ],
      "metadata": {
        "id": "AZBXhgrfTKoQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyyXkObVRS6p"
      },
      "outputs": [],
      "source": [
        "# necessary package for DL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "import math\n",
        "import sys\n",
        "import pandas as pd # used for handling the dataset\n",
        "import numpy as np # used for handling numbers\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import random\n",
        "\n",
        "\n",
        "# added import\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
        "import time\n",
        "from typing import Dict, Optional, Tuple\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_path=\"/content/drive/MyDrive/UNSW_NB15/UNSW_NB15_training-set.csv\"\n",
        "dataset_path2=\"/content/drive/MyDrive/UNSW_NB15/UNSW_NB15_testing_set.csv\"\n",
        "\n",
        "dataset_train  = pd.read_csv(dataset_path)\n",
        "dataset_test   = pd.read_csv(dataset_path2)\n",
        "frames         = [dataset_train, dataset_test]\n",
        "dataset_all    = pd.concat(frames)"
      ],
      "metadata": {
        "id": "D-bN0ZhNRcFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop null values\n",
        "dataset_all = dataset_all.dropna()\n",
        "# this should contain only 2 value 0 or 1 since its a bollean attributs\n",
        "dataset_all.is_ftp_login = dataset_all.is_ftp_login.replace({2.0: 1.0})\n",
        "#keep attack_cat for further use\n",
        "df_attack_cat = dataset_all['attack_cat']\n",
        "# peut faussé les résultats\n",
        "dataset_all = dataset_all.drop('attack_cat', axis=1)\n",
        "# peut faussé les résultats\n",
        "dataset_all = dataset_all.drop('id', axis=1)\n",
        "# récupérer les données catgoriques\n",
        "dataset_cat = dataset_all[['proto','service','state']]\n",
        "# récupérer les valeurs bolléen\n",
        "dataset_bool = dataset_all[['is_ftp_login','is_sm_ips_ports']]\n",
        "# récupérer la target\n",
        "df_y = dataset_all['label']\n",
        "\n",
        "# supprimée les features qui peuvents faussée nos résultats\n",
        "dataset_num = dataset_all.drop('proto', axis=1)\n",
        "dataset_num = dataset_num.drop('service', axis=1)\n",
        "dataset_num = dataset_num.drop('state', axis=1)\n",
        "dataset_num = dataset_num.drop('is_ftp_login', axis=1)\n",
        "dataset_num = dataset_num.drop('is_sm_ips_ports', axis=1)\n",
        "dataset_num = dataset_num.drop('label', axis=1)\n",
        "\n",
        "# transforme cat to num\n",
        "transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "transformed = transformer.fit_transform(dataset_cat).toarray()\n",
        "df_cat = pd.DataFrame(transformed, columns=transformer.get_feature_names_out())\n",
        "\n",
        "# normalize the dataset\n",
        "oe = StandardScaler()\n",
        "transformed = oe.fit_transform(dataset_num)\n",
        "df_num = pd.DataFrame(transformed, columns=dataset_num.columns)\n",
        "\n",
        "df_all = pd.concat([df_cat, df_num], axis=1)\n",
        "df_all['is_ftp_login']    = dataset_bool['is_ftp_login'].values\n",
        "df_all['is_sm_ips_ports'] = dataset_bool['is_sm_ips_ports'].values"
      ],
      "metadata": {
        "id": "Thr03kDnRfuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_X, df_test_X, df_train_y, df_test_y = train_test_split(df_all, df_y, test_size=0.2)\n",
        "\n",
        "# taille du model\n",
        "taille_variable1 = sys.getsizeof(df_train_X)\n",
        "taille_variable2 = sys.getsizeof(df_train_y)\n",
        "taille_total = taille_variable1 + taille_variable2\n",
        "print(f\"La taille du model est : {taille_total} octets\")"
      ],
      "metadata": {
        "id": "pkd-5XpD9fRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = 194\n",
        "model = Sequential()\n",
        "model.add(Dense(150, input_dim=input, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(120, activation='relu'))\n",
        "model.add(Dense(90, activation='relu'))\n",
        "model.add(Dense(60, activation='relu'))\n",
        "model.add(Dense(30, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                    tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                    tf.keras.metrics.Precision(),\n",
        "                                                                    tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                    tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                    tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "start_time = time.time()\n",
        "model.fit(df_train_X, df_train_y, epochs=100)\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "# temps d'execution\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "# taille du model\n",
        "taille_variable = sys.getsizeof(model)\n",
        "print(f\"La taille de la variable est : {taille_variable} octets\")\n",
        "loss, acc, auc, precision, recall, tp, tn, fp, fn= model.evaluate(df_test_X, df_test_y, verbose=2)\n",
        "\n",
        "# Making predictions on the test set to obtain probabilities\n",
        "predictions_proba = model.predict(df_test_X).ravel()\n",
        "# Deriving classes based on a threshold (e.g., 0.5)\n",
        "predictions = np.where(predictions_proba >= 0.5, 1, 0)\n",
        "# Calculating F1 score\n",
        "f1 = f1_score(df_test_y, predictions)\n",
        "# print f1 score\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "MwOPg7rMSMlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FL IDS"
      ],
      "metadata": {
        "id": "mzX_kfbOTO_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setup FL"
      ],
      "metadata": {
        "id": "sl5QhPIeFsJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap"
      ],
      "metadata": {
        "id": "CuFt99GqT3Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install flwr[\"simulation\"]"
      ],
      "metadata": {
        "id": "Z45S1Wbq9ycA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import flwr as fl"
      ],
      "metadata": {
        "id": "yJhg9YXw9ylN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn):\n",
        "  print(\"==============list_f1_score=================\")\n",
        "  for i in list_f1_score :\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_auc==============\")\n",
        "  for i in list_auc:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_precision==============\")\n",
        "  for i in list_precision:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_recall==============\")\n",
        "  for i in list_recall:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_tp==============\")\n",
        "  for i in list_tp:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_tn==============\")\n",
        "  for i in list_tn:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_fp==============\")\n",
        "  for i in list_fp:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_fn==============\")\n",
        "  for i in list_fn:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "zEbdQeD19yn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=1, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}"
      ],
      "metadata": {
        "id": "JdY3zEBw9yqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func_client_fn(model_fl, x_train_all, y_train_all):\n",
        "\n",
        "  x_train_all = x_train_all\n",
        "  y_train_all = y_train_all\n",
        "\n",
        "  def client_fn(cid: str) -> fl.client.Client:\n",
        "\n",
        "      print('########################################## cid= ',cid,' ##########################################')\n",
        "      # Load data partition (divide dataset into NUM_CLIENTS distinct partitions)\n",
        "      partition_size = math.floor(len(x_train_all) / NUM_CLIENTS)\n",
        "      idx_from, idx_to = int(cid) * partition_size, (int(cid) + 1) * partition_size\n",
        "      x_train_all_part = x_train_all[idx_from:idx_to]\n",
        "      y_train_all_part = y_train_all[idx_from:idx_to]\n",
        "\n",
        "      x_train_all_part, X_test_all, y_train_all_part, y_test_all = train_test_split(x_train_all, y_train_all, test_size=0.1)\n",
        "\n",
        "      # Create and return client\n",
        "      return FlowerClient(model_fl, x_train_all_part, y_train_all_part, X_test_all, y_test_all)\n",
        "\n",
        "  return client_fn"
      ],
      "metadata": {
        "id": "DihSy0xp9yst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_eval_fn(model, x_test_arr_val, y_test_arr_val):\n",
        "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
        "    global list_f1_score\n",
        "    global list_auc\n",
        "    global list_precision\n",
        "    global list_recall\n",
        "    global list_tp\n",
        "    global list_tn\n",
        "    global list_fp\n",
        "    global list_fn\n",
        "    global model_xai\n",
        "\n",
        "    x_test_arr_val = x_test_arr_val\n",
        "    y_test_arr_val = y_test_arr_val\n",
        "\n",
        "\n",
        "    # The `evaluate` function will be called after every round\n",
        "    def evaluate(server_round: int, parameters: fl.common.NDArrays, config: Dict[str, fl.common.Scalar],) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "\n",
        "        model.set_weights(parameters)  # Update model with the latest parameters\n",
        "        loss, accuracy, auc, precision, recall, tp, tn, fp, fn = model.evaluate(x_test_arr_val, y_test_arr_val)\n",
        "\n",
        "        # Making predictions on the test set to obtain probabilities\n",
        "        predictions_proba = model.predict(x_test_arr_val).ravel()\n",
        "\n",
        "        # Deriving classes based on a threshold (e.g., 0.5)\n",
        "        predictions = np.where(predictions_proba >= 0.5, 1, 0)\n",
        "\n",
        "        # Calculating F1 score\n",
        "        f1 = f1_score(y_test_arr_val, predictions)\n",
        "        list_f1_score.append(f1)\n",
        "        list_auc.append(auc)\n",
        "        list_precision.append(precision)\n",
        "        list_recall.append(recall)\n",
        "        list_tp.append(tp)\n",
        "        list_tn.append(tn)\n",
        "        list_fp.append(fp)\n",
        "        list_fn.append(fn)\n",
        "\n",
        "        if accuracy > 0.9881 :\n",
        "          model_xai = model\n",
        "          sys.exit()\n",
        "\n",
        "\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "\n",
        "    return evaluate"
      ],
      "metadata": {
        "id": "CyNb7D7K9yvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_f1_score =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (x_fraction, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    input = 194\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(150, input_dim=input, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(120, activation='relu'))\n",
        "    model_cent.add(Dense(90, activation='relu'))\n",
        "    model_cent.add(Dense(60, activation='relu'))\n",
        "    model_cent.add(Dense(30, activation='relu'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='sigmoid'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=x_fraction,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=100),\n",
        "        strategy=strategy,\n",
        "    )\n",
        "\n",
        "    print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "LLCnhKeY9yxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test number of clients"
      ],
      "metadata": {
        "id": "ibFTJNy8FwvG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### number of clients = 2"
      ],
      "metadata": {
        "id": "933VeyyoF0PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 2\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "lMnM_8rJ9y0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "ZaKO8TV09y2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### number of clients = 4"
      ],
      "metadata": {
        "id": "y2dZcbYeF67V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 4\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "aRCSCUHv9y5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "xnZX5RCX9y76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### number of clients = 8"
      ],
      "metadata": {
        "id": "ZxsMbJAu-Ukd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 8\n",
        "start_time = time.time()\n",
        "FL_process(0.1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "S7RyGhRm-VWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "CE_zqQ_f-VZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### number of clients = 12"
      ],
      "metadata": {
        "id": "_HnCOPVF5yyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 12\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "O1izzJN4524z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "lNrCDFs255g2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test fraction fit"
      ],
      "metadata": {
        "id": "mTLkZzGLGGny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fraction fit = 0.1"
      ],
      "metadata": {
        "id": "N55dDDPxGJsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 12\n",
        "start_time = time.time()\n",
        "FL_process(0.1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "8Aktqq7n-VbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "jUO07X1M-Veg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fraction fit = 0.5"
      ],
      "metadata": {
        "id": "kVEwpAggJcAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "FL_process(0.5, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "HJhEokaUJlkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "yG88zWWuJlsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fraction fit = 1"
      ],
      "metadata": {
        "id": "vB4lLTUvJcL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "YtyOCINYJn5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "KD3Oy4OrJoCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test local epochs"
      ],
      "metadata": {
        "id": "0RPGrwrZn4_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### local epochs = 1"
      ],
      "metadata": {
        "id": "ZVge-znSH7uS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=1, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "\n",
        "list_f1_score =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (x_fraction, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    input = 194\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(150, input_dim=input, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(120, activation='relu'))\n",
        "    model_cent.add(Dense(90, activation='relu'))\n",
        "    model_cent.add(Dense(60, activation='relu'))\n",
        "    model_cent.add(Dense(30, activation='relu'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='sigmoid'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=x_fraction,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=100),\n",
        "        strategy=strategy,\n",
        "    )"
      ],
      "metadata": {
        "id": "dbvsWOZaITKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 12\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "R7TttEl6ozTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "-UkqIb7Ao2DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### local epcohs = 2"
      ],
      "metadata": {
        "id": "LHM7lLWvpSXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=2, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "\n",
        "list_f1_score =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (x_fraction, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    input = 194\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(150, input_dim=input, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(120, activation='relu'))\n",
        "    model_cent.add(Dense(90, activation='relu'))\n",
        "    model_cent.add(Dense(60, activation='relu'))\n",
        "    model_cent.add(Dense(30, activation='relu'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='sigmoid'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=x_fraction,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=100),\n",
        "        strategy=strategy,\n",
        "    )"
      ],
      "metadata": {
        "id": "SsRKB2MDpVGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 12\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "OiSACWuDphYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "eLAVIZTBpi1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### colcal epochs = 5"
      ],
      "metadata": {
        "id": "815QDMLIpjVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=5, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "\n",
        "list_f1_score =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (x_fraction, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    input = 194\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(150, input_dim=input, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(120, activation='relu'))\n",
        "    model_cent.add(Dense(90, activation='relu'))\n",
        "    model_cent.add(Dense(60, activation='relu'))\n",
        "    model_cent.add(Dense(30, activation='relu'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='sigmoid'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=x_fraction,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=100),\n",
        "        strategy=strategy,\n",
        "    )"
      ],
      "metadata": {
        "id": "ou7qDMaepraI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 12\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "oaKaRXblpn0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "PgSZ5tlwpqAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### local epochs = 8"
      ],
      "metadata": {
        "id": "Ij2yDE6ZpwuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=8, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "\n",
        "list_f1_score =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (x_fraction, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    input = 194\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(150, input_dim=input, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(120, activation='relu'))\n",
        "    model_cent.add(Dense(90, activation='relu'))\n",
        "    model_cent.add(Dense(60, activation='relu'))\n",
        "    model_cent.add(Dense(30, activation='relu'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='sigmoid'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=x_fraction,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=100),\n",
        "        strategy=strategy,\n",
        "    )"
      ],
      "metadata": {
        "id": "_YD1J08Dp87v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 12\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "qzDMjT_5p7Rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "pmUAU-cDp7dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XAI"
      ],
      "metadata": {
        "id": "MQnmUMCjPLKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=1, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "list_f1_score =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (x_fraction, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    input = 194\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(150, input_dim=input, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(120, activation='relu'))\n",
        "    model_cent.add(Dense(90, activation='relu'))\n",
        "    model_cent.add(Dense(60, activation='relu'))\n",
        "    model_cent.add(Dense(30, activation='relu'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='sigmoid'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=x_fraction,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=100),\n",
        "        strategy=strategy,\n",
        "    )\n",
        "\n",
        "    print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "KpwgSRslPMoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 8\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "nGFdvPyIHaFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "UsRzgKXyPnxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "explainer   = shap.Explainer(model_xai, df_train_X.values)\n",
        "shap_values = explainer(df_test_X)\n",
        "\n",
        "shap.plots.beeswarm(shap_values)\n",
        "shap.plots.bar(shap_values)"
      ],
      "metadata": {
        "id": "LppYl1GA-dt0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}