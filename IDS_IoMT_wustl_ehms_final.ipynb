{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "z43A2BEB4OCk",
        "YOpONCyd4SMq",
        "mOh8x0sSbLU4",
        "gwVfVqSfZXMB",
        "e4g38xlKZa90",
        "1WcIjrLdZgV0",
        "KItquJPZZtdl",
        "9UpQUK1lqDjy",
        "DWKUvMEOaA4F",
        "fIeza4ZVaFFi",
        "YRl1V8LCDa40",
        "2G_60jtjD1WR",
        "wU2xpzEwEQ1k",
        "boPr2U7MEp5K",
        "1bxKbHoLam6L"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# centralized IDS"
      ],
      "metadata": {
        "id": "z43A2BEB4OCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # used for handling the dataset\n",
        "import numpy as np # used for handling numbers\n",
        "\n",
        "import time\n",
        "import warnings\n",
        "from collections import Counter\n",
        "import sys\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelEncoder, OneHotEncoder #, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "from sklearn.base import clone\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import xgboost as xgb\n",
        "\n",
        "# necessary package for DL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#import flwr as fl\n",
        "import math\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "from typing import Dict, Optional, Tuple\n",
        "\n",
        "# added import\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
        "import time\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "sh3owtaR3wAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rA5cKBI53l9C"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataset_path=\"/content/drive/MyDrive/wustl-ehms-2020 - Copie.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_val = pd.read_csv(dataset_path)\n",
        "\n",
        "#34 for all feature + label\n",
        "dataset           = pd.DataFrame(data=dataset_val,columns=['SrcBytes','DstBytes','SrcLoad','DstLoad', 'SrcGap', 'DstGap', 'SIntPkt', 'DIntPkt', 'SIntPktAct', 'DIntPktAct', 'SrcJitter', 'DstJitter', 'sMaxPktSz', 'dMaxPktSz', 'sMinPktSz', 'dMinPktSz', 'Dur', 'Trans', 'TotPkts', 'TotBytes', 'Loss', 'pLoss', 'pSrcLoss', 'pDstLoss', 'Rate', 'Load', 'Temp', 'SpO2', 'Pulse_Rate', 'SYS', 'DIA', 'Heart_rate', 'Resp_Rate', 'ST', 'Label'])"
      ],
      "metadata": {
        "id": "1mHbmLiV3z9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare input data\n",
        "def prepare_inputs(X_train):\n",
        "    oe = StandardScaler()\n",
        "    oe.fit(X_train)\n",
        "    X_train_enc = oe.transform(X_train)\n",
        "    return X_train_enc"
      ],
      "metadata": {
        "id": "_1rPMPw63276"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = dataset['Label']\n",
        "dataset_val = pd.DataFrame(data=dataset_val,columns=['SrcBytes','DstBytes','SrcLoad','DstLoad', 'SrcGap', 'DstGap', 'SIntPkt', 'DIntPkt', 'SIntPktAct', 'DIntPktAct', 'SrcJitter', 'DstJitter', 'sMaxPktSz', 'dMaxPktSz', 'sMinPktSz', 'dMinPktSz', 'Dur', 'Trans', 'TotPkts', 'TotBytes', 'Loss', 'pLoss', 'pSrcLoss', 'pDstLoss', 'Rate', 'Load', 'Temp', 'SpO2', 'Pulse_Rate', 'SYS', 'DIA', 'Heart_rate', 'Resp_Rate', 'ST'])\n",
        "val = prepare_inputs(dataset_val.values)\n",
        "dataset_val_norm = pd.DataFrame(data=val,columns=['SrcBytes','DstBytes','SrcLoad','DstLoad', 'SrcGap', 'DstGap', 'SIntPkt', 'DIntPkt', 'SIntPktAct', 'DIntPktAct', 'SrcJitter', 'DstJitter', 'sMaxPktSz', 'dMaxPktSz', 'sMinPktSz', 'dMinPktSz', 'Dur', 'Trans', 'TotPkts', 'TotBytes', 'Loss', 'pLoss', 'pSrcLoss', 'pDstLoss', 'Rate', 'Load', 'Temp', 'SpO2', 'Pulse_Rate', 'SYS', 'DIA', 'Heart_rate', 'Resp_Rate', 'ST'])\n",
        "dataset_val_norm['Label'] = label.values\n"
      ],
      "metadata": {
        "id": "OrR8uswk35Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = dataset_val_norm['Label']\n",
        "x = dataset_val_norm.drop  ('Label' , axis=1)"
      ],
      "metadata": {
        "id": "l0x_BWi937oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_X, df_test_X, df_train_y, df_test_y = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "# taille du model\n",
        "taille_variable1 = sys.getsizeof(df_train_X)\n",
        "taille_variable2 = sys.getsizeof(df_train_y)\n",
        "taille_total = taille_variable1 + taille_variable2\n",
        "print(f\"La taille du model est : {taille_total} octets\")"
      ],
      "metadata": {
        "id": "pjh3_-YQ397-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(40, input_dim=34, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                    tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                    tf.keras.metrics.Precision(),\n",
        "                                                                    tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                    tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                    tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "model.fit(df_train_X, df_train_y, epochs=15) #15\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "# temps d'execution\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "# taille du model\n",
        "taille_variable = sys.getsizeof(model)\n",
        "print(f\"La taille de la variable est : {taille_variable} octets\")\n",
        "loss, acc, auc, precision, recall, tp, tn, fp, fn= model.evaluate(df_test_X, df_test_y, verbose=2)\n",
        "\n",
        "# Making predictions on the test set to obtain probabilities\n",
        "predictions_proba = model.predict(df_test_X).ravel()\n",
        "# Deriving classes based on a threshold (e.g., 0.5)\n",
        "predictions = np.where(predictions_proba >= 0.5, 1, 0)\n",
        "# Calculating F1 score\n",
        "f1 = f1_score(df_test_y, predictions)\n",
        "# print f1 score\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "JCAlhHDb4ACn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FL IDS"
      ],
      "metadata": {
        "id": "YOpONCyd4SMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup FL"
      ],
      "metadata": {
        "id": "mOh8x0sSbLU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap"
      ],
      "metadata": {
        "id": "pxcyb74c4CfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install flwr[\"simulation\"]"
      ],
      "metadata": {
        "id": "KoPUN21lpkZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import flwr as fl"
      ],
      "metadata": {
        "id": "k_nVfR4dpmtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn):\n",
        "  print(\"==============list_f1_score=================\")\n",
        "  for i in list_f1_score :\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_auc==============\")\n",
        "  for i in list_auc:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_precision==============\")\n",
        "  for i in list_precision:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_recall==============\")\n",
        "  for i in list_recall:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_tp==============\")\n",
        "  for i in list_tp:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_tn==============\")\n",
        "  for i in list_tn:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_fp==============\")\n",
        "  for i in list_fp:\n",
        "    print(i)\n",
        "\n",
        "  print(\"==============list_fn==============\")\n",
        "  for i in list_fn:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "HC0CE93ypodT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=1, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}"
      ],
      "metadata": {
        "id": "kszCKSuppo4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def func_client_fn(model_fl, x_train_all, y_train_all):\n",
        "\n",
        "  x_train_all = x_train_all\n",
        "  y_train_all = y_train_all\n",
        "\n",
        "  def client_fn(cid: str) -> fl.client.Client:\n",
        "\n",
        "      print('########################################## cid= ',cid,' ##########################################')\n",
        "      # Load data partition (divide dataset into NUM_CLIENTS distinct partitions)\n",
        "      partition_size = math.floor(len(x_train_all) / NUM_CLIENTS)\n",
        "      idx_from, idx_to = int(cid) * partition_size, (int(cid) + 1) * partition_size\n",
        "      x_train_all_part = x_train_all[idx_from:idx_to]\n",
        "      y_train_all_part = y_train_all[idx_from:idx_to]\n",
        "\n",
        "      x_train_all_part, X_test_all, y_train_all_part, y_test_all = train_test_split(x_train_all, y_train_all, test_size=0.1)\n",
        "\n",
        "      # Create and return client\n",
        "      return FlowerClient(model_fl, x_train_all_part, y_train_all_part, X_test_all, y_test_all)\n",
        "\n",
        "  return client_fn"
      ],
      "metadata": {
        "id": "958PPEAppo6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_eval_fn(model, x_test_arr_val, y_test_arr_val):\n",
        "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
        "    global list_f1_score\n",
        "    global list_auc\n",
        "    global list_precision\n",
        "    global list_recall\n",
        "    global list_tp\n",
        "    global list_tn\n",
        "    global list_fp\n",
        "    global list_fn\n",
        "    global model_xai\n",
        "\n",
        "    x_test_arr_val = x_test_arr_val\n",
        "    y_test_arr_val = y_test_arr_val\n",
        "\n",
        "\n",
        "    # The `evaluate` function will be called after every round\n",
        "    def evaluate(server_round: int, parameters: fl.common.NDArrays, config: Dict[str, fl.common.Scalar],) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "\n",
        "        model.set_weights(parameters)  # Update model with the latest parameters\n",
        "        loss, accuracy, auc, precision, recall, tp, tn, fp, fn = model.evaluate(x_test_arr_val, y_test_arr_val)\n",
        "\n",
        "        # Making predictions on the test set to obtain probabilities\n",
        "        predictions_proba = model.predict(x_test_arr_val).ravel()\n",
        "\n",
        "        # Deriving classes based on a threshold (e.g., 0.5)\n",
        "        predictions = np.where(predictions_proba >= 0.5, 1, 0)\n",
        "\n",
        "        # Calculating F1 score\n",
        "        f1 = f1_score(y_test_arr_val, predictions)\n",
        "        list_f1_score.append(f1)\n",
        "        list_auc.append(auc)\n",
        "        list_precision.append(precision)\n",
        "        list_recall.append(recall)\n",
        "        list_tp.append(tp)\n",
        "        list_tn.append(tn)\n",
        "        list_fp.append(fp)\n",
        "        list_fn.append(fn)\n",
        "\n",
        "        if accuracy > 0.9378 :\n",
        "          model_xai = model\n",
        "          sys.exit()\n",
        "\n",
        "\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "\n",
        "    return evaluate"
      ],
      "metadata": {
        "id": "vmUd1Mbtpo9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_f1_score =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (x_fraction, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(40, input_dim=34, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='sigmoid'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=x_fraction,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=50),\n",
        "        strategy=strategy,\n",
        "    )\n",
        "\n",
        "    print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "p7uqWPPxpo_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test number of clients"
      ],
      "metadata": {
        "id": "gwVfVqSfZXMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test number of clients = 2 & fraction fit = 1 & local epochs = 1"
      ],
      "metadata": {
        "id": "e4g38xlKZa90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 2\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "yS0CGPA8ppLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "gbfPvMMd8sfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test number of clients = 4 & fraction fit = 1 & local epochs = 1"
      ],
      "metadata": {
        "id": "1WcIjrLdZgV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 4\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "vF0aCYMCppN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "lxjVC_VO8uZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test number of clients = 8 & fraction fit = 1 & local epochs = 1"
      ],
      "metadata": {
        "id": "KItquJPZZtdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 8\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "R8nNhBFwZuti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "z2LT8pAgZvDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test fractions fit"
      ],
      "metadata": {
        "id": "9UpQUK1lqDjy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fractions fit = 0.1 & number of clients = 8 & local epochs = 1"
      ],
      "metadata": {
        "id": "DWKUvMEOaA4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 8\n",
        "start_time = time.time()\n",
        "FL_process(0.1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "-ZqPpvhtqDu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "iNLhX0Ar8zxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fractions fit = 0.5 & number of clients = 8 & local epochs = 1"
      ],
      "metadata": {
        "id": "fIeza4ZVaFFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "FL_process(0.5, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "8RgpeWP5qD3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temps d'execution\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "H9t70K3U82hE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fractions fit = 1 & number of clients = 8 & local epochs = 1\n",
        "- aleardy tested"
      ],
      "metadata": {
        "id": "pJWUeNNJawzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test number of local epochs"
      ],
      "metadata": {
        "id": "YRl1V8LCDa40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### local epochs = 1 & number of clients = 8 & fraction fit = 1\n",
        "- aleardy tested"
      ],
      "metadata": {
        "id": "DGnxzz4cDek4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### local epochs = 2 & number of clients = 8 & fraction fit = 1"
      ],
      "metadata": {
        "id": "2G_60jtjD1WR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=2, verbose=0)\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "list_f1_score =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (x_fraction, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(40, input_dim=34, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='sigmoid'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=x_fraction,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=50),\n",
        "        strategy=strategy,\n",
        "    )"
      ],
      "metadata": {
        "id": "eViFxoGWEFcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 8\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "QbkMWZkBENmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "7UAhr3_0EOrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### local epochs = 5 & number of clients = 8 & fraction fit = 1"
      ],
      "metadata": {
        "id": "wU2xpzEwEQ1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=5, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "list_f1_score =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (x_fraction, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(40, input_dim=34, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='sigmoid'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=x_fraction,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=50),\n",
        "        strategy=strategy,\n",
        "    )"
      ],
      "metadata": {
        "id": "jAgylY_SETQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 8\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "ynMN1dqZEVmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "Ep1ILeITEVwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### local epcohs = 8 & number of clients = 8 & fraction fit = 1"
      ],
      "metadata": {
        "id": "boPr2U7MEp5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=8, verbose=0)\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "list_f1_score =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (x_fraction, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(40, input_dim=34, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='sigmoid'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=x_fraction,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),  # Wait until at least 75 clients are available\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=NUM_CLIENTS,\n",
        "        config=fl.server.ServerConfig(num_rounds=50),\n",
        "        strategy=strategy,\n",
        "    )"
      ],
      "metadata": {
        "id": "xLzhKYYpXv7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 8\n",
        "start_time = time.time()\n",
        "FL_process(1, NUM_CLIENTS, df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "bist6VvmXwGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "OARZKnXbXwTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XAI"
      ],
      "metadata": {
        "id": "1bxKbHoLam6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, x_train, y_train, x_val, y_val) -> None:\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model = model\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_val, self.y_val = x_val, y_val\n",
        "\n",
        "    def get_parameters(self):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.x_train, self.y_train, epochs=8, verbose=0) #15 epochs\n",
        "\n",
        "        taille_variable1 = sys.getsizeof(self.x_train)\n",
        "        taille_variable2 = sys.getsizeof(self.y_train)\n",
        "        taille_totale = taille_variable1 + taille_variable2\n",
        "        print(f\"La taille du training data est : {taille_totale} octets\")\n",
        "\n",
        "        taille_variable3 = sys.getsizeof(self.model.get_weights())\n",
        "        print(f\"La taille des weights du model est : {taille_variable3} octets\")\n",
        "\n",
        "        return self.model.get_weights(), len(self.x_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        warnings.filterwarnings('ignore')\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, acc, auc, precision, recall, tp, tn, fp, fn= self.model.evaluate(self.x_val, self.y_val, verbose=2)\n",
        "        return loss, len(self.x_val), {\"accuracy\": acc}\n",
        "\n",
        "\n",
        "list_f1_score =[]\n",
        "list_auc=[]\n",
        "list_precision=[]\n",
        "list_recall=[]\n",
        "list_tp=[]\n",
        "list_tn=[]\n",
        "list_fp=[]\n",
        "list_fn=[]\n",
        "\n",
        "def FL_process (df_train_X, df_train_y, df_test_X, df_test_y):\n",
        "\n",
        "    model_cent = Sequential()\n",
        "    model_cent.add(Dense(40, input_dim=34, activation='relu', kernel_initializer='he_normal'))\n",
        "    model_cent.add(Dense(20, activation='relu'))\n",
        "    model_cent.add(Dense(10, activation='relu'))\n",
        "    model_cent.add(Dense(1, activation='sigmoid'))\n",
        "    model_cent.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\",\n",
        "                                                                            tf.keras.metrics.AUC(from_logits=True),\n",
        "                                                                            tf.keras.metrics.Precision(),\n",
        "                                                                            tf.keras.metrics.Recall(), tf.keras.metrics.TruePositives(),\n",
        "                                                                            tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(),\n",
        "                                                                            tf.keras.metrics.FalseNegatives()])\n",
        "\n",
        "    model_xai = model_cent\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy=fl.server.strategy.FedAvg(\n",
        "            fraction_fit=1,\n",
        "            min_fit_clients=2,\n",
        "            min_available_clients=int(NUM_CLIENTS * 0.75),\n",
        "            evaluate_fn = get_eval_fn(model_cent, df_test_X, df_test_y),\n",
        "            initial_parameters=fl.common.ndarrays_to_parameters(model_cent.get_weights()),\n",
        "    )\n",
        "\n",
        "    # Start simulation\n",
        "\n",
        "    fl.simulation.start_simulation(\n",
        "        client_fn=func_client_fn(model_cent, df_train_X, df_train_y),\n",
        "        num_clients=8,\n",
        "        config=fl.server.ServerConfig(num_rounds=50),\n",
        "        strategy=strategy,\n",
        "    )"
      ],
      "metadata": {
        "id": "8Wg3flpiEr4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "FL_process(df_train_X, df_train_y, df_test_X, df_test_y)"
      ],
      "metadata": {
        "id": "6WE1YE9-EwTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
        "print_results (list_f1_score, list_auc, list_precision, list_recall, list_tp, list_tn, list_fp, list_fn)"
      ],
      "metadata": {
        "id": "ZVchjLRuEwb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "explainer   = shap.Explainer(model_xai, df_train_X.values)\n",
        "shap_values = explainer(df_test_X)\n",
        "\n",
        "shap.plots.beeswarm(shap_values, max_display=30)\n",
        "shap.plots.bar(shap_values)"
      ],
      "metadata": {
        "id": "mLWoFyVyqLnb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}